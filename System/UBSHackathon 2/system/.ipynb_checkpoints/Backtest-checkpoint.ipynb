{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T14:05:43.500040Z",
     "start_time": "2019-10-13T14:05:43.493503Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle \n",
    "import time \n",
    "import statsmodels.tsa.stattools\n",
    "import statsmodels.graphics.tsaplots\n",
    "import sys\n",
    "import warnings\n",
    "from gurobipy import * \n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T14:05:43.857741Z",
     "start_time": "2019-10-13T14:05:43.844812Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T14:05:44.151227Z",
     "start_time": "2019-10-13T14:05:44.141568Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize backtest\n",
    "Principal = 1000000 \n",
    "\n",
    "# arima training days\n",
    "arima_days = 30 \n",
    "\n",
    "# model param\n",
    "model_param_dict = {\n",
    "    'theta': 0.5, # theta means the obj weights in alpha, i.e how importance is alpha in the obj\n",
    "    'market_ub': 0.5, \n",
    "    'market_lb': 0, \n",
    "    'weight_ub': 0.05,  # buy 20 stocks at least\n",
    "    'weight_lb': 0,  # buy 100 stocks at most\n",
    "    'trans_cost': 0.01, \n",
    "    'bigM': 10, \n",
    "    'sector_ub': 0.3, \n",
    "    'sector_lb': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T14:06:09.077722Z",
     "start_time": "2019-10-13T14:05:57.972315Z"
    }
   },
   "outputs": [],
   "source": [
    "stock_df = pd.read_csv(DATA_PATH + 'totalPrice.csv').rename(columns={'Unnamed: 0': 'Code'}).set_index('Code')\n",
    "stock_df = stock_df.drop('2019-01-01 00:00:00', axis=1)\n",
    "\n",
    "stock_df = stock_df.T.iloc[-arima_days-5:].T\n",
    "\n",
    "# load in the backtest dataset\n",
    "OpenPrice = pd.read_excel(DATA_PATH + 'openPrice_USD.xlsx',header=0,index_col=0)\n",
    "OpenPrice = OpenPrice.drop('IBKR UW Equity', axis=0).reset_index().set_index('index')\n",
    "ClosePrice = pd.read_excel(DATA_PATH + 'closePrice_USD.xlsx',header=0,index_col=0)\n",
    "ClosePrice = ClosePrice.drop('IBKR UW Equity', axis=0).reset_index().set_index('index')\n",
    "Benchmark = pd.read_excel(DATA_PATH + 'MSCI_World_NTR.xlsx',header=0)\n",
    "\n",
    "# stock name arr \n",
    "with open(DATA_PATH + 'stock_name_arr.pkl', 'rb') as file:\n",
    "    stock_name_arr = pickle.load(file)\n",
    "    \n",
    "# Covariance matrix \n",
    "with open(DATA_PATH + 'cov_mat.pkl', 'rb') as file:\n",
    "    cov_mat_arr = pickle.load(file)\n",
    "\n",
    "# market dict\n",
    "with open(DATA_PATH + 'market_dict.pkl', 'rb') as file:\n",
    "    market_dict = pickle.load(file)\n",
    "    \n",
    "# sector dict\n",
    "with open(DATA_PATH + 'sector_dict.pkl', 'rb') as file:\n",
    "    sector_dict = pickle.load(file) \n",
    "    \n",
    "data_dict = {\n",
    "    'stock_name_arr': stock_name_arr, \n",
    "    'cov_mat_arr': cov_mat_arr, \n",
    "    'market_dict': market_dict, \n",
    "    'sector_dict': sector_dict\n",
    "}\n",
    "del stock_name_arr \n",
    "del cov_mat_arr \n",
    "del market_dict \n",
    "del sector_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T14:06:09.474006Z",
     "start_time": "2019-10-13T14:06:09.430402Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a series for the 1-lag difference\n",
    "def draw_acf_pacf(ts, lags=31):\n",
    "    f = plt.figure(facecolor='white')\n",
    "    ax1 = f.add_subplot(211)\n",
    "    statsmodels.graphics.tsaplots.plot_acf(ts, lags=31, ax=ax1)\n",
    "    ax2 = f.add_subplot(212)\n",
    "    statsmodels.graphics.tsaplots.plot_pacf(ts, lags=31, ax=ax2)\n",
    "    plt.show()\n",
    "\n",
    "def testStationarity(time_series):\n",
    "    dftest = statsmodels.tsa.stattools.adfuller(time_series)\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    return dfoutput\n",
    "\n",
    "\n",
    "def proper_model(data_ts, maxLag_p = 5, maxLag_q = 5):\n",
    "    init_aic = sys.maxsize\n",
    "    init_p = 0\n",
    "    init_q = 0\n",
    "    init_properModel = None\n",
    "    for p in np.arange(maxLag_p):\n",
    "        for q in np.arange(maxLag_q):\n",
    "            try:\n",
    "                model = statsmodels.tsa.arima_model.ARMA(data_ts, order=(p, q), freq = 'D')\n",
    "                results_ARMA = model.fit(disp=-1, method='css')\n",
    "                aic = results_ARMA.aic\n",
    "                if aic < init_aic:\n",
    "                    init_p = p\n",
    "                    init_q = q\n",
    "                    init_properModel = results_ARMA\n",
    "                    init_aic = aic\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    return init_properModel, init_p, init_q\n",
    "\n",
    "def diff_to_stationary(ts):\n",
    "    if(testStationarity(ts)['p-value'] <= 0.05):\n",
    "        return ts,0\n",
    "    else:\n",
    "        ts_diff = ts.diff(1).dropna()\n",
    "        num = 1\n",
    "        while(testStationarity(ts_diff)['p-value'] > 0.05):\n",
    "            ts_diff = ts_diff.diff(1).dropna()\n",
    "            num += 1\n",
    "        return ts_diff, num \n",
    "    \n",
    "def arima_main(df):\n",
    "    df = df.T \n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    cols = df.columns.to_list()\n",
    "    df = df.reset_index(drop=False)\n",
    "    df.rename(columns={'index':'DATE'}, inplace = True)\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    \n",
    "    def arima_predict(ric, training_days=arima_days):\n",
    "        start = time.time()\n",
    "        close_price = df[['DATE', ric]]\n",
    "        helper = pd.DataFrame({'DATE': pd.date_range(close_price['DATE'].min(), close_price['DATE'].max())})\n",
    "        close_price = pd.merge(close_price, helper, on='DATE', how='outer').sort_values('DATE')\n",
    "        close_price[ric] = close_price[ric].interpolate(method='linear')   \n",
    "        close_price.set_index(pd.to_datetime(close_price.DATE), inplace=True) # set the index to be the DATE\n",
    "        close_price.sort_index(inplace=True)  # sort the dataframe by the newly created datetime index\n",
    "\n",
    "\n",
    "        last_date = close_price.index.to_list()[-1] - timedelta(days=training_days)\n",
    "        close_price = close_price[close_price.index >= last_date] \n",
    "        ts = close_price[ric]\n",
    "        ts.index = pd.to_datetime(close_price.index)\n",
    "\n",
    "        ts_diff, num_of_diff = diff_to_stationary(ts)\n",
    "\n",
    "        inf_lst = proper_model(ts_diff)\n",
    "        \n",
    "        current = close_price.index.to_list()[-1]\n",
    "        end_time = current\n",
    "        day1 = current + timedelta(days = 1)\n",
    "        day2 = current + timedelta(days = 2)\n",
    "        day3 = current + timedelta(days = 3)\n",
    "        day4 = current + timedelta(days = 4)\n",
    "        day5 = current + timedelta(days = 5)\n",
    "\n",
    "        try:\n",
    "            predict_ts = inf_lst[0].predict(day1, day5, dynamic=True)\n",
    "        except AttributeError:\n",
    "            print('No appropriate model')\n",
    "            return -1\n",
    "\n",
    "        for i in range(num_of_diff):\n",
    "            if(num_of_diff - i - 1 != 0):\n",
    "                predict_ts[day1] = predict_ts[day1] + ts.diff(num_of_diff - i)[end_time]\n",
    "            else:\n",
    "                predict_ts[day1] = predict_ts[day1] + ts[end_time]\n",
    "            predict_ts[day2] = predict_ts[day2] + predict_ts[day1]\n",
    "            predict_ts[day3] = predict_ts[day3] + predict_ts[day2]\n",
    "            predict_ts[day4] = predict_ts[day4] + predict_ts[day3]\n",
    "            predict_ts[day5] = predict_ts[day5] + predict_ts[day4]\n",
    "        return (predict_ts[day5] - ts[end_time]) / ts[end_time]\n",
    "    \n",
    "    pred_dict = {}\n",
    "    for i in range(len(cols)):\n",
    "        col = cols[i]\n",
    "        if i % 100 == 0.:\n",
    "            print(f'    The {i}th predictions ... ')\n",
    "        pred_dict[col] = arima_predict(col)\n",
    "        \n",
    "    return pred_dict\n",
    "# pred_dict = arima_main(stock_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T14:06:09.752573Z",
     "start_time": "2019-10-13T14:06:09.715945Z"
    }
   },
   "outputs": [],
   "source": [
    "class PortOpt:\n",
    "    def __init__(self, data_dict, p_dict, init_port_=None):\n",
    "        # params retrieve\n",
    "        self.theta = p_dict['theta']\n",
    "        self.market_ub = p_dict['market_ub']\n",
    "        self.market_lb = p_dict['market_lb']\n",
    "        self.weight_ub = p_dict['weight_ub']\n",
    "        self.weight_lb = p_dict['weight_lb']\n",
    "        self.sector_ub = p_dict['sector_ub']\n",
    "        self.sector_lb = p_dict['sector_lb']\n",
    "        self.trans_cost = p_dict['trans_cost']\n",
    "        self.bigM = p_dict['bigM']\n",
    "    \n",
    "        # stock and market information retrieve\n",
    "        self.stock_arr = data_dict['stock_name_arr']  # index of w\n",
    "        self.stock_idx_arr = np.arange(0, len(self.stock_arr))\n",
    "        \n",
    "        self.alpha_dict = data_dict['alpha_dict']\n",
    "        self.alpha_idx_dict = {}\n",
    "        for idx in self.stock_idx_arr:\n",
    "            key = self.stock_arr[idx]\n",
    "            self.alpha_idx_dict[idx] = self.alpha_dict[key]\n",
    "        self.cov_mat_arr = data_dict['cov_mat_arr']\n",
    "        \n",
    "        self.sector_dict = data_dict['sector_dict']\n",
    "        self.sector_idx_dict = {}\n",
    "        for key in self.sector_dict:\n",
    "            arr = self.sector_dict[key]\n",
    "            self.sector_idx_dict[key] = [np.where(self.stock_arr==i)[0][0] for i in arr]\n",
    "            \n",
    "        self.market_dict = data_dict['market_dict']\n",
    "        self.market_idx_dict = {}\n",
    "        for key in self.market_dict:\n",
    "            arr = self.market_dict[key]\n",
    "            self.market_idx_dict[key] = [np.where(self.stock_arr==i)[0][0] for i in arr]\n",
    "        \n",
    "        # port model \n",
    "        self.model = Model('Port Opt Model')\n",
    "        self.init_port = init_port_\n",
    "        self.var_dict = {} \n",
    "        self.__model_init()\n",
    "\n",
    "    def optimize(self):\n",
    "        self.model.optimize()\n",
    "        \n",
    "    def __model_init(self):\n",
    "        self.__create_vars()\n",
    "        self.__create_constrs()\n",
    "        self.__create_obj()\n",
    "        self.model.update()\n",
    "\n",
    "    def __get_market_stock(self):  # TODO\n",
    "        # return dict of arrays\n",
    "        # keys of dict is the same as msci_dict\n",
    "        pass  \n",
    "        \n",
    "    def __create_vars(self):\n",
    "        # portfolio weights\n",
    "#         self.var_dict['w'] = self.model.addVars(self.stock_idx_arr, vtype=GRB.CONTINUOUS, lb=0.0, name='w')\n",
    "        self.var_dict['w'] = pd.Series(self.model.addVars(self.stock_idx_arr, name='w', lb=0.0, vtype=GRB.CONTINUOUS), index=self.stock_idx_arr)\n",
    "        # portfolio change\n",
    "        if self.init_port is None:\n",
    "            pass \n",
    "        else:\n",
    "            # portfolio change = last port - current port (only consider the sells part)\n",
    "            self.var_dict['y'] = self.model.addVars(self.stock_idx_arr, vtype=GRB.CONTINUOUS, lb=0.0, name='y')\n",
    "\n",
    "            # artificial var \n",
    "            self.var_dict['z'] = self.model.addVars(self.stock_idx_arr, vtype=GRB.BINARY, name='z')\n",
    "        \n",
    "        self.model.update()\n",
    "        \n",
    "    def __create_constrs(self):\n",
    "        # 1 weights normalization\n",
    "        self.model.addConstr(sum([self.var_dict['w'][i] for i in self.stock_idx_arr]) == 1, name='1_weights_normalization')\n",
    "        \n",
    "        # 2 limit weights per market\n",
    "        for key in self.market_idx_dict:\n",
    "            market_arr = self.market_idx_dict[key]\n",
    "            self.model.addConstr((sum([self.var_dict['w'][i] for i in market_arr]) <= self.market_ub), name='2_1_weights_{}_market_ub'.format(key))\n",
    "            self.model.addConstr((sum([self.var_dict['w'][i] for i in market_arr]) >= self.market_lb), name='2_1_weights_{}_market_lb'.format(key))\n",
    "        \n",
    "        # 3 limit weights per share \n",
    "        self.model.addConstrs((self.var_dict['w'][i] <= self.weight_ub for i in self.stock_idx_arr), name='3_weight_per_asset_ub')\n",
    "        \n",
    "        # 4 y = max{0, init_port - current port}\n",
    "        if self.init_port is None:\n",
    "            pass \n",
    "        else:\n",
    "            self.model.addConstrs((self.init_port[i] - self.var_dict['w'][i] <= self.bigM * (1 - self.var_dict['z']) for i in self.stock_idx_arr), name='4c{}'.format(i))\n",
    "            self.model.addConstrs((-self.var_dict['y'][i] + self.init_port[i] - self.var_dict['w'][i] <= self.bigM * self.var_dict['z'] for i in selff.stock_idx_arr), name='4b{}'.format(i))\n",
    "            self.model.addConstrs((self.var_dict['y'][i] - self.init_port[i] + self.var_dict['w'][i] <= self.bigM * self.var_dict['z'] for i in selff.stock_idx_arr), name='4a{}'.format(i))\n",
    "\n",
    "        # 5 limit weights per sector\n",
    "        for key in self.sector_idx_dict:\n",
    "            sector_arr = self.sector_idx_dict[key]\n",
    "            self.model.addConstr((sum([self.var_dict['w'][i] for i in sector_arr]) <= self.sector_ub), name='5_weights_{}_sector_ub'.format(key))\n",
    "            self.model.addConstr((sum([self.var_dict['w'][i] for i in sector_arr]) >= self.sector_lb), name='5_weights_{}_sector_lb'.format(key))\n",
    "        \n",
    "        self.model.update()\n",
    "\n",
    "    def __create_obj(self):\n",
    "        min_obj = self.cov_mat_arr.dot(self.var_dict['w']).dot(self.var_dict['w'])\n",
    "        max_obj = np.array(list(data_dict['alpha_dict'].values())).dot(self.var_dict['w'])\n",
    "        # transaction cost\n",
    "        if self.init_port is None:\n",
    "            cost = 0 \n",
    "        else:\n",
    "            cost = np.sum([self.var_dict['y'][i] * self.trans_cost for i in self.stock_idx_arr])\n",
    "\n",
    "        obj = self.theta * (max_obj - cost) - (1 - self.theta) * min_obj\n",
    "        \n",
    "        self.model.setObjective(obj, GRB.MAXIMIZE)\n",
    "        self.model.update()\n",
    "    \n",
    "    def get_results(self):\n",
    "        temp_results_list = [self.var_dict['w'][i].x for i in self.stock_idx_arr]\n",
    "        results_arr = []\n",
    "        for i in temp_results_list:\n",
    "            if i > 1e-10: \n",
    "                results_arr.append(i)\n",
    "            else:\n",
    "                results_arr.append(0)\n",
    "        return self.stock_arr, np.array(results_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T14:06:10.015991Z",
     "start_time": "2019-10-13T14:06:10.009387Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_main():\n",
    "    print('Start predicting the expected 5-day return ... ')\n",
    "    alpha_dict = arima_main(stock_df)\n",
    "    with open(DATA_PATH + 'alpha.pkl', 'wb') as file:\n",
    "        pickle.dump(alpha_dict, file)\n",
    "    data_dict['alpha_dict'] = alpha_dict\n",
    "    print('Start Portfolio Model ... ')\n",
    "    port = PortOpt(data_dict, model_param_dict)\n",
    "    port.optimize()\n",
    "    stock_arr, results_arr = port.get_results()\n",
    "    return results_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T14:06:10.639330Z",
     "start_time": "2019-10-13T14:06:10.621438Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def MaxDrawdown(trading_days, return_list):\n",
    "    '''return_list is a 1-Dimension list or np.array'''\n",
    "    i = np.argmax((np.maximum.accumulate(return_list) - return_list) / np.maximum.accumulate(return_list))  # 结束位置\n",
    "    if i == 0:\n",
    "        return 0\n",
    "    j = np.argmax(return_list[:i])  # 开始位置\n",
    "    Max_Drawdown_Rate = (return_list[j] - return_list[i]) / (return_list[j])  # 最大回撤率\n",
    "    plt.plot(trading_days, return_list)\n",
    "    plt.title(\"Max Drawdown\", color='k', size=15)\n",
    "    plt.xlabel(\"Date\", size=10)\n",
    "    plt.ylabel(\"Net Worth\", size=10)\n",
    "    plt.plot([trading_days[i], trading_days[j]], [return_list[i], return_list[j]], 'o', color=\"r\", markersize=10)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    return Max_Drawdown_Rate\n",
    "\n",
    "def SharpeRatio(return_list):\n",
    "    '''SharpeRatio=[E(Rp)－Rf]/σp'''\n",
    "    returns = (return_list[1:]-return_list[:-1])/return_list[:-1]   # 每日收益\n",
    "    average_return = np.mean(returns)\n",
    "    return_stdev = np.std(returns)\n",
    "#  上面得出的夏普比率是以日为单位，我们需要将其年化\n",
    "    AnnualRet = average_return*252               # 默认252个工作日\n",
    "    AnnualVol = return_stdev*np.sqrt(252)        # 默认US Treasury Yields为1.5%\n",
    "    sharpe_ratio = (AnnualRet-0.015) /AnnualVol  # 夏普比率\n",
    "    return sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-13T14:06:14.652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting the expected 5-day return ... \n",
      "    The 0th predictions ... \n",
      "    The 100th predictions ... \n",
      "    The 200th predictions ... \n"
     ]
    }
   ],
   "source": [
    "Net_Asset_List = [Principal]\n",
    "# build the initial investment pool\n",
    "port_arr = model_main()\n",
    "init_port = port_arr * Principal\n",
    "range_list = OpenPrice.columns.to_list() # convert all the trading days to a list\n",
    "open_price = OpenPrice[range_list[0]].values\n",
    "holding_shares = init_port / open_price\n",
    "close_price = ClosePrice[range_list[0]].values\n",
    "temp = holding_shares * close_price\n",
    "Principal = np.sum(temp) # sum up the net worth each day after the market close\n",
    "print(f'Date {range_list[0]} has principal {Principal}')\n",
    "last_port = temp / Principal\n",
    "Net_Asset_List.append(Principal) # store the net worth of the day\n",
    "print(Net_Asset_List)\n",
    "# update training set\n",
    "# Add the close_price, which is a 1-D np.array, to your dataset!\n",
    "stock_df[range_list[0]] = ClosePrice[range_list[0]]\n",
    "stock_df = stock_df.T.iloc[1:].T\n",
    "\n",
    "# rolling over each day\n",
    "# You could set range_list[1:] to range_list[1:20] for test purpose\n",
    "for idx, date in enumerate(range_list[1:]):\n",
    "    print(f'########## POSSESSING DATE: {date} ##########')\n",
    "    # model results\n",
    "    port_arr = model_main()\n",
    "    # change of portfolio\n",
    "    change_arr = port_arr - last_port  # buy and sell info stored in change_arr\n",
    "    change_dollars = Principal * change_arr\n",
    "    open_price = OpenPrice[date].values\n",
    "    change_shares = change_dollars / open_price\n",
    "    holding_shares += change_shares\n",
    "    # calculate the net worth after the market closes\n",
    "    close_price = ClosePrice[date].values\n",
    "    temp = holding_shares * close_price\n",
    "    Principal = np.sum(temp) # sum up the net worth each day after the market close\n",
    "    print(f'Date {date} has principal {Principal}')\n",
    "    last_port = temp / Principal\n",
    "    Net_Asset_List.append(Principal) # store the net worth of the day\n",
    "    print(Net_Asset_List)\n",
    "    # update training set\n",
    "    # Add the close_price, which is a 1-D np.array, to your dataset!\n",
    "    stock_df[date] = ClosePrice[date]\n",
    "    stock_df = stock_df.T.iloc[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-13T06:20:26.183Z"
    }
   },
   "outputs": [],
   "source": [
    "# What I need here is just 'Net_Asset_List' calculated above\n",
    "Date = Benchmark['Date'].values\n",
    "MSCI_Returns = Benchmark['Benchmark Return'].values\n",
    "print(\"The Max Drawdown of our quantitative strategy is: \", MaxDrawdown(Date, Net_Asset_List[1:]))\n",
    "print(\"The Sharpe Ratio of our quantitative strategy is: \", SharpeRatio(Net_Asset_List))\n",
    "Net_Asset_Array = np.array(Net_Asset_List)\n",
    "Strat_Daily_Returns = (Net_Asset_Array[1:]-Net_Asset_Array[0])/Net_Asset_Array[0]\n",
    "\n",
    "# Plot the return curve\n",
    "plt.plot(Date, MSCI_Returns, 'y-', linewidth=1.5, label=\"Benchmark\")\n",
    "plt.plot(Date, Strat_Daily_Returns, 'r-', linewidth=1.8, label=\"Strategy\")\n",
    "plt.legend()\n",
    "plt.title(\"The Return Curve\", color='k', size=15)\n",
    "plt.xlabel(\"Date\", size=10)\n",
    "plt.ylabel(\"Returns\", size=10)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
